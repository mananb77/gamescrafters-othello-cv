{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Othello Computer Vision Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (1.26.3)\n",
      "Requirement already satisfied: matplotlib in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (3.8.2)\n",
      "Requirement already satisfied: scipy in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (1.11.4)\n",
      "Requirement already satisfied: opencv-python in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: opencv-python-headless in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: Pillow in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (10.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/mananbhargava/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy matplotlib scipy opencv-python opencv-python-headless Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries here\n",
    "\n",
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "\traise Exception(\"Python 3 not detected.\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from scipy import io\n",
    "import scipy\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to:\n",
    "1. Load the image\n",
    "2. Get the corners of the image\n",
    "3. Divide it into the 4x4 grid\n",
    "4. Analyze the pixels for each grid square\n",
    "5. Determine if the piece is black or white or empty\n",
    "6. Create the game state string\n",
    "7. Return the state of the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Image & Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 12:07:28.684 Python[23286:5179037] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "image = cv2.imread('images/random-board-gamesman-uni.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply GaussianBlur to reduce noise and improve edge detection\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Detect edges using Canny edge detector\n",
    "edges = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
    "\n",
    "# Find contours based on edges detected\n",
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Assuming the largest contour is the board, find its bounding box\n",
    "board_contour = max(contours, key=cv2.contourArea)\n",
    "x, y, w, h = cv2.boundingRect(board_contour)\n",
    "\n",
    "# Crop the image to the board's bounding box (optional, for further processing)\n",
    "board = image[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imshow('Board', board)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Grid Detection and Piece Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     game_state[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# White piece, noting [i, j] for row i, column j\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mgame_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '-'"
     ]
    }
   ],
   "source": [
    "# w is the width from above\n",
    "# h is the height of the image from above\n",
    "\n",
    "grid_size = 4\n",
    "square_width, square_height = w // grid_size, h // grid_size\n",
    "\n",
    "# 0 for empty, 1 for black, 2 for white\n",
    "game_state = np.zeros((grid_size, grid_size), dtype=int)  \n",
    "\n",
    "# Convert the whole board image to HSV for better color segmentation\n",
    "hsv_board = cv2.cvtColor(board, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define color ranges for black and white pieces\n",
    "# Note: These ranges might need adjustment based on your lighting conditions and camera\n",
    "black_lower, black_upper = np.array([0, 0, 0]), np.array([180, 255, 50])\n",
    "white_lower, white_upper = np.array([0, 0, 200]), np.array([180, 25, 255])\n",
    "\n",
    "# Create masks for black and white for the whole board\n",
    "black_mask = cv2.inRange(hsv_board, black_lower, black_upper)\n",
    "white_mask = cv2.inRange(hsv_board, white_lower, white_upper)\n",
    "\n",
    "\n",
    "# What we hope to accomplish\n",
    "# Convert the whole board image to a mask to determine black pieces\n",
    "# Convert the whole board image to a mask to determine white pieces \n",
    "for i in range(grid_size):  # i for rows\n",
    "    for j in range(grid_size):  # j for columns\n",
    "        # Define the pixel range for the current square\n",
    "        start_x, start_y = j * square_width, i * square_height\n",
    "        end_x, end_y = (j + 1) * square_width, (i + 1) * square_height\n",
    "\n",
    "        # Access the relevant section of the black and white masks\n",
    "        black_mask_square = black_mask[start_y:end_y, start_x:end_x]\n",
    "        white_mask_square = white_mask[start_y:end_y, start_x:end_x]\n",
    "\n",
    "        # Determine if square is black, white, or empty based on the mask\n",
    "        if np.sum(black_mask_square) > 100:  # Adjust threshold based on your conditions\n",
    "            game_state[i, j] = 'b'  # Black piece, noting [i, j] for row i, column j\n",
    "        elif np.sum(white_mask_square) > 100:  # Adjust threshold based on your conditions\n",
    "            game_state[i, j] = 'w'  # White piece, noting [i, j] for row i, column j\n",
    "        else:\n",
    "            game_state[i, j] = '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert Gamestate 2D Array into 1D String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 2D array into 1D array\n",
    "flattened_game_state = game_state.flatten(game_state.shape[0])\n",
    "\n",
    "# Use the .join method to convert to a string\n",
    "game_state_string = ''.join(flattened_game_state)\n",
    "\n",
    "print(game_state_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gamestate_from_board_image(url):\n",
    "  # -----------------------------------------------\n",
    "  # Step 1: Load Image\n",
    "  \n",
    "  # Load the image\n",
    "  image = cv2.imread(url)\n",
    "\n",
    "  # -----------------------------------------------\n",
    "  # Step 2: Edge Detection\n",
    "\n",
    "  # Convert to grayscale\n",
    "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "  blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "  # Detect edges using Canny edge detector\n",
    "  edges = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
    "\n",
    "  # Find contours based on edges detected\n",
    "  contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "  # Assuming the largest contour is the board, find its bounding box\n",
    "  board_contour = max(contours, key=cv2.contourArea)\n",
    "  x, y, w, h = cv2.boundingRect(board_contour)\n",
    "\n",
    "  # Crop the image to the board's bounding box (optional, for further processing)\n",
    "  board = image[y:y+h, x:x+w]\n",
    "\n",
    "  cv2.imshow('Board', board)\n",
    "  cv2.waitKey(0)\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "  # -----------------------------------------------\n",
    "  # Step 3: Grid Detection and Piece Recognition\n",
    "  \n",
    "  # w is the width from above\n",
    "  # h is the height of the image from above\n",
    "\n",
    "  grid_size = 4\n",
    "  square_width, square_height = w // grid_size, h // grid_size\n",
    "\n",
    "  # 0 for empty, 1 for black, 2 for white\n",
    "  game_state = np.zeros((grid_size, grid_size), dtype=int)  \n",
    "\n",
    "  # Convert the whole board image to HSV for better color segmentation\n",
    "  hsv_board = cv2.cvtColor(board, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "  # Define color ranges for black and white pieces\n",
    "  # Note: These ranges might need adjustment based on your lighting conditions and camera\n",
    "  black_lower, black_upper = np.array([0, 0, 0]), np.array([180, 255, 50])\n",
    "  white_lower, white_upper = np.array([0, 0, 200]), np.array([180, 25, 255])\n",
    "\n",
    "  # Create masks for black and white for the whole board\n",
    "  black_mask = cv2.inRange(hsv_board, black_lower, black_upper)\n",
    "  white_mask = cv2.inRange(hsv_board, white_lower, white_upper)\n",
    "\n",
    "\n",
    "  # What we hope to accomplish\n",
    "  # Convert the whole board image to a mask to determine black pieces\n",
    "  # Convert the whole board image to a mask to determine white pieces \n",
    "  for i in range(grid_size):  # i for rows\n",
    "      for j in range(grid_size):  # j for columns\n",
    "          # Define the pixel range for the current square\n",
    "          start_x, start_y = j * square_width, i * square_height\n",
    "          end_x, end_y = (j + 1) * square_width, (i + 1) * square_height\n",
    "\n",
    "          # Access the relevant section of the black and white masks\n",
    "          black_mask_square = black_mask[start_y:end_y, start_x:end_x]\n",
    "          white_mask_square = white_mask[start_y:end_y, start_x:end_x]\n",
    "\n",
    "          # Determine if square is black, white, or empty based on the mask\n",
    "          if np.sum(black_mask_square) > 100:  # Adjust threshold based on your conditions\n",
    "              game_state[i, j] = 'b'  # Black piece, noting [i, j] for row i, column j\n",
    "          elif np.sum(white_mask_square) > 100:  # Adjust threshold based on your conditions\n",
    "              game_state[i, j] = 'w'  # White piece, noting [i, j] for row i, column j\n",
    "          else:\n",
    "              game_state[i, j] = '-'\n",
    "\n",
    "  # Flatten the 2D array into 1D array\n",
    "  flattened_game_state = game_state.flatten(game_state.shape[0])\n",
    "\n",
    "  # Use the .join method to convert to a string\n",
    "  game_state_string = ''.join(flattened_game_state)\n",
    "\n",
    "  return game_state_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create List of AutoGUI Moves from Recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first frame of your original game state position string\n",
    "Save the current game position string\n",
    "The user makes their move\n",
    "Once the pieces have stopped updating, then after x milliseconds for the animated version to change, then look at frame after (I estimate between 30 to 35 milliseconds for the update to occur)\n",
    "Save the post-move game position string\n",
    "Look at the difference between the two game state strings, where the grid square has changed from a ‘-’, empty spot, to either ‘W’ or ‘B’ depending on who’s turn it was for example:\n",
    "--B--BB--WWW---- \n",
    "--B--BB--WBW---B\n",
    "We conclude that the player added a new piece in index 15\n",
    "Construct the autoguiDovie\n",
    "Therefore, the game move was:\n",
    "autoguiMove: A_h_15_x\n",
    "Repeat this process through analyzing the entire game’s recording\n",
    "Build a list of the autogui Moves "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get a before and after frame of the image\n",
    "2. Calculate game strings\n",
    "3. Calculate difference between game strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_move_from_two_frames(url1, url2):\n",
    "  # Load the two frames\n",
    "  # frame1 = cv2.imread(url1)\n",
    "  # frame2 = cv2.imread(url2)\n",
    "\n",
    "  str1 = get_gamestate_from_board_image(url1)\n",
    "  str2 = get_gamestate_from_board_image(url2)\n",
    "\n",
    "  # Compare both the strings for a difference\n",
    "  # Ensure both strings are of the same length\n",
    "  if len(str1) != len(str2):\n",
    "      print(\"Error: Strings are of different lengths.\")\n",
    "      return\n",
    "\n",
    "  move_index = None\n",
    "  check_count = 0\n",
    "\n",
    "  # Iterate through each character in the strings\n",
    "  for i in range(len(str1)):\n",
    "      if str1[i] == '-' and str2[i] in ['B', 'W']:\n",
    "          move_index = i\n",
    "          print(f\"Position {i}: '-' changed to '{str2[i]}'\")\n",
    "          check_count += 1\n",
    "    \n",
    "  # In case we made an error\n",
    "  if (check_count > 1):\n",
    "      print(\"We made 2 or more changes to determining the move here\")\n",
    "      print(str(check_count))\n",
    "  \n",
    "  # Create the auto_gui move\n",
    "  auto_gui_move = 'A_h_' + str(move_index) + '_x'\n",
    "\n",
    "  return auto_gui_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through video & identify frames for update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_all_frames(video_path, output_folder):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # If frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            break  # Exit the loop if there are no frames left to read\n",
    "        \n",
    "        # Construct the output filename\n",
    "        output_filename = f\"{output_folder}/frame_{frame_count:04d}.jpg\"\n",
    "        \n",
    "        # Save the frame to disk\n",
    "        cv2.imwrite(output_filename, frame)\n",
    "        \n",
    "        # Increment the frame count\n",
    "        frame_count += 1\n",
    "    \n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Total frames saved: {frame_count}\")\n",
    "\n",
    "# Example usage\n",
    "video_path = 'path_to_your_video.mp4'\n",
    "output_folder = 'path_to_output_folder'\n",
    "extract_and_save_all_frames(video_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_states = []\n",
    "auto_gui_moves = []\n",
    "\n",
    "# Pass in the auto gui moves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
